Python 3.7.11 (default, Jul 27 2021, 14:32:16) 
Type "copyright", "credits" or "license" for more information.

IPython 7.31.1 -- An enhanced Interactive Python.

runfile('/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/script_call_optionCGMY.py', wdir='/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP')
  0%|          | 0/8001 [00:00<?, ?it/s]2022-10-05 17:43:30.860380: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: 
2022-10-05 17:43:30.860404: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2022-10-05 17:43:30.860421: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (linux1): /proc/driver/nvidia/version does not exist
2022-10-05 17:43:30.860664: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2022-10-05 17:43:30.883890: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz
2022-10-05 17:43:30.892278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5612b6112f20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-10-05 17:43:30.892325: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  0%|          | 0/8001 [00:00<?, ?it/s]
Traceback (most recent call last):

  File "/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/script_call_optionCGMY.py", line 73, in <module>
    training_history = bsde_solver.train()

  File "/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/PureJumpSolver.py", line 36, in train
    loss = self.loss_fn(valid_data, training=False).numpy()

  File "/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/PureJumpSolver.py", line 49, in loss_fn
    y_terminal, penalty = self.model(inputs, training)

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 968, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
    result = self._call(*args, **kwds)

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 506, in _initialize
    *args, **kwds))

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 3299, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)

  File "/opt/anaconda3/envs/tensorflow2_env/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)

AttributeError: in user code:

    /home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/PureJumpSolver.py:96 call  *
        z = self.subnet[t].grad(x[:, :, t]) * self.bsde.getFsdeDiffusion(t,x[:, :, t])/ self.bsde.dim
    /home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/PureJumpEquation_CGMYprova.py:329 getFsdeDiffusion  *
        return self.sigmaEpsSq * x #il sigma deve essere il sigma calcolato con il CGMY cioè quello che in matlab è sigmaEpsSq dentro pathsimulation

    AttributeError: 'CallOptionCGMY' object has no attribute 'sigmaEpsSq'





Removing all variables...
 



runfile('/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/script_call_optionCGMY.py', wdir='/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP')
Reloaded modules: PureJumpSolver, PureJumpEquation_CGMYprova, equation, tmp413k80ys, tmpix2z_z92, tmpfdedimip, tmp3rku4aw0
/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/PureJumpEquation_CGMYprova.py:287: RuntimeWarning: overflow encountered in exp
  T= np.exp(M*(X-eps))
  0%|          | 0/8001 [00:00<?, ?it/s]WARNING:tensorflow:AutoGraph could not transform <bound method NonsharedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f05342cda90>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <bound method NonsharedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f05342cda90>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <bound method FeedForwardSubNet.call of <PureJumpSolver.FeedForwardSubNet object at 0x7f05adf88f50>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <bound method FeedForwardSubNet.call of <PureJumpSolver.FeedForwardSubNet object at 0x7f05adf88f50>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <bound method FeedForwardSubNet.grad of <PureJumpSolver.FeedForwardSubNet object at 0x7f05adf88f50>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <bound method FeedForwardSubNet.grad of <PureJumpSolver.FeedForwardSubNet object at 0x7f05adf88f50>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
step:     0,    loss: 6.4498e+01, Y0: -1.0690e-01,   elapsed time: 130
  1%|          | 64/8001 [08:37<52:42,  2.51it/s]     /home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/PureJumpEquation_CGMYprova.py:292: RuntimeWarning: overflow encountered in exp
  T= np.exp(M*(X-eps))
  1%|          | 100/8001 [08:52<59:22,  2.22it/s] step:   100,    loss: 1.3263e-01, Y0: -5.9074e-02,   elapsed time: 534
  2%|▏         | 200/8001 [09:30<45:43,  2.84it/s]  step:   200,    loss: 2.4844e-01, Y0: -3.2551e-02,   elapsed time: 572
  4%|▎         | 300/8001 [10:07<46:31,  2.76it/s]  step:   300,    loss: 4.0542e-01, Y0: -5.5398e-02,   elapsed time: 609
  5%|▍         | 400/8001 [10:45<44:47,  2.83it/s]  step:   400,    loss: 4.6950e-01, Y0: 1.3586e-03,   elapsed time: 646
  6%|▌         | 500/8001 [11:22<46:42,  2.68it/s]  step:   500,    loss: 3.4747e-01, Y0: 8.7414e-02,   elapsed time: 683
  7%|▋         | 600/8001 [12:00<44:17,  2.79it/s]  step:   600,    loss: 1.0589e-01, Y0: 4.3389e-02,   elapsed time: 721
  9%|▊         | 700/8001 [12:37<43:43,  2.78it/s]  step:   700,    loss: 7.4601e-02, Y0: 2.6947e-02,   elapsed time: 758
 10%|▉         | 800/8001 [13:13<40:42,  2.95it/s]  step:   800,    loss: 1.5060e-01, Y0: -1.6233e-02,   elapsed time: 795
 11%|█         | 900/8001 [13:50<41:22,  2.86it/s]  step:   900,    loss: 2.1803e-01, Y0: 1.5720e-01,   elapsed time: 832
 12%|█▏        | 1000/8001 [14:28<43:05,  2.71it/s] step:  1000,    loss: 2.0619e-01, Y0: -7.0169e-02,   elapsed time: 869
 14%|█▎        | 1100/8001 [15:04<41:18,  2.78it/s]  step:  1100,    loss: 3.9017e-01, Y0: 1.0875e-01,   elapsed time: 906
 15%|█▍        | 1200/8001 [15:41<39:53,  2.84it/s]  step:  1200,    loss: 1.9023e-01, Y0: -9.7725e-02,   elapsed time: 942
 16%|█▌        | 1300/8001 [16:18<43:26,  2.57it/s]  step:  1300,    loss: 7.4599e-02, Y0: 4.0996e-01,   elapsed time: 980
 17%|█▋        | 1400/8001 [16:57<42:11,  2.61it/s]  step:  1400,    loss: 2.4385e-01, Y0: -4.1480e-01,   elapsed time: 1019
 19%|█▊        | 1500/8001 [17:35<39:09,  2.77it/s]  step:  1500,    loss: 3.7167e-01, Y0: -5.0438e-02,   elapsed time: 1057
 20%|█▉        | 1600/8001 [18:12<37:45,  2.83it/s]  step:  1600,    loss: 1.6740e+01, Y0: -1.0841e+00,   elapsed time: 1094
 21%|██        | 1700/8001 [18:49<36:24,  2.88it/s]  step:  1700,    loss: 1.1607e+01, Y0: 9.7073e-02,   elapsed time: 1130
 22%|██▏       | 1800/8001 [19:24<35:30,  2.91it/s]step:  1800,    loss: 3.7678e-01, Y0: 8.0117e-02,   elapsed time: 1165
 24%|██▎       | 1900/8001 [20:01<36:48,  2.76it/s]step:  1900,    loss: 8.9068e-01, Y0: 1.5052e-01,   elapsed time: 1202
 25%|██▍       | 2000/8001 [20:38<36:31,  2.74it/s]step:  2000,    loss: 8.2367e-02, Y0: 2.9383e-02,   elapsed time: 1240
 26%|██▌       | 2100/8001 [21:17<38:24,  2.56it/s]step:  2100,    loss: 2.2000e-01, Y0: 1.5544e-01,   elapsed time: 1278
 27%|██▋       | 2200/8001 [21:55<35:51,  2.70it/s]step:  2200,    loss: 4.5082e+00, Y0: 9.8825e-02,   elapsed time: 1316
 29%|██▊       | 2300/8001 [22:32<35:22,  2.69it/s]step:  2300,    loss: 6.3883e+00, Y0: 1.1883e-01,   elapsed time: 1353
 30%|██▉       | 2400/8001 [23:10<34:33,  2.70it/s]step:  2400,    loss: 3.5897e-01, Y0: 1.9751e-01,   elapsed time: 1391
 31%|███       | 2500/8001 [23:47<33:11,  2.76it/s]step:  2500,    loss: 1.3025e-01, Y0: 1.1008e-01,   elapsed time: 1428
 32%|███▏      | 2600/8001 [24:24<32:21,  2.78it/s]step:  2600,    loss: 1.2964e+00, Y0: 6.0694e-02,   elapsed time: 1465
 34%|███▎      | 2700/8001 [25:00<31:51,  2.77it/s]step:  2700,    loss: 5.2765e+00, Y0: 2.3435e-01,   elapsed time: 1501
 35%|███▍      | 2800/8001 [25:35<30:31,  2.84it/s]step:  2800,    loss: 4.8748e-01, Y0: 1.9027e-01,   elapsed time: 1536
 36%|███▌      | 2900/8001 [26:12<31:27,  2.70it/s]step:  2900,    loss: 7.9291e-02, Y0: 1.8971e-01,   elapsed time: 1573
 37%|███▋      | 3000/8001 [26:48<30:06,  2.77it/s]step:  3000,    loss: 6.1886e+00, Y0: 7.2795e-01,   elapsed time: 1609
 39%|███▊      | 3100/8001 [27:25<29:14,  2.79it/s]step:  3100,    loss: 3.8921e-01, Y0: 1.5560e-01,   elapsed time: 1646
 40%|███▉      | 3200/8001 [28:00<26:59,  2.96it/s]step:  3200,    loss: 9.4065e-02, Y0: 1.8323e-01,   elapsed time: 1681
 41%|████      | 3300/8001 [28:36<28:02,  2.79it/s]step:  3300,    loss: 1.1307e-01, Y0: 2.4496e-01,   elapsed time: 1717
 42%|████▏     | 3400/8001 [29:12<26:26,  2.90it/s]step:  3400,    loss: 1.8531e-01, Y0: 3.7088e-01,   elapsed time: 1753
 44%|████▎     | 3500/8001 [29:48<28:22,  2.64it/s]step:  3500,    loss: 1.2185e+00, Y0: 8.9563e-02,   elapsed time: 1790
 45%|████▍     | 3600/8001 [30:24<24:48,  2.96it/s]step:  3600,    loss: 4.2599e-01, Y0: 1.0742e-01,   elapsed time: 1825
 46%|████▌     | 3700/8001 [31:00<24:37,  2.91it/s]step:  3700,    loss: 1.4151e+00, Y0: 2.6224e-01,   elapsed time: 1861
 47%|████▋     | 3800/8001 [31:37<25:23,  2.76it/s]step:  3800,    loss: 2.5195e+00, Y0: 2.0486e-01,   elapsed time: 1899
 49%|████▊     | 3900/8001 [32:14<24:26,  2.80it/s]step:  3900,    loss: 7.2808e-02, Y0: 1.9001e-01,   elapsed time: 1936
 50%|████▉     | 4000/8001 [32:52<24:35,  2.71it/s]step:  4000,    loss: 1.1790e+01, Y0: 2.0523e-02,   elapsed time: 1973
 51%|█████     | 4100/8001 [33:29<23:26,  2.77it/s]step:  4100,    loss: 1.3331e-01, Y0: 6.5141e-02,   elapsed time: 2011
 52%|█████▏    | 4200/8001 [34:07<22:52,  2.77it/s]step:  4200,    loss: 1.4466e-01, Y0: 5.9455e-02,   elapsed time: 2048
 54%|█████▎    | 4300/8001 [34:43<22:59,  2.68it/s]step:  4300,    loss: 4.8023e-02, Y0: 7.7379e-02,   elapsed time: 2084
 55%|█████▍    | 4400/8001 [35:21<22:12,  2.70it/s]step:  4400,    loss: 5.3378e-02, Y0: 7.3296e-02,   elapsed time: 2122
 56%|█████▌    | 4500/8001 [35:57<22:11,  2.63it/s]step:  4500,    loss: 4.3354e-02, Y0: 7.6912e-02,   elapsed time: 2159
 57%|█████▋    | 4600/8001 [36:35<20:17,  2.79it/s]step:  4600,    loss: 8.7631e-02, Y0: 8.8587e-02,   elapsed time: 2196
 59%|█████▊    | 4700/8001 [37:12<19:28,  2.82it/s]step:  4700,    loss: 4.9863e-02, Y0: 8.7266e-02,   elapsed time: 2234
 60%|█████▉    | 4800/8001 [37:49<19:11,  2.78it/s]step:  4800,    loss: 9.3004e-02, Y0: 8.3869e-02,   elapsed time: 2271
 61%|██████    | 4900/8001 [38:27<19:00,  2.72it/s]step:  4900,    loss: 1.8614e-01, Y0: 8.7133e-02,   elapsed time: 2308
 62%|██████▏   | 5000/8001 [39:04<18:21,  2.73it/s]step:  5000,    loss: 3.1622e-02, Y0: 9.2164e-02,   elapsed time: 2345
 64%|██████▎   | 5100/8001 [39:41<17:47,  2.72it/s]step:  5100,    loss: 3.0013e-02, Y0: 9.1589e-02,   elapsed time: 2383
 65%|██████▍   | 5200/8001 [40:19<17:31,  2.66it/s]step:  5200,    loss: 6.4168e-02, Y0: 9.5245e-02,   elapsed time: 2420
 66%|██████▌   | 5300/8001 [40:56<16:27,  2.74it/s]step:  5300,    loss: 5.8699e-02, Y0: 1.0222e-01,   elapsed time: 2458
 67%|██████▋   | 5400/8001 [41:34<16:34,  2.62it/s]step:  5400,    loss: 1.1300e-01, Y0: 1.0541e-01,   elapsed time: 2496
 69%|██████▊   | 5500/8001 [42:13<15:52,  2.62it/s]step:  5500,    loss: 4.7342e-02, Y0: 1.0145e-01,   elapsed time: 2534
 70%|██████▉   | 5600/8001 [42:50<14:42,  2.72it/s]step:  5600,    loss: 1.0477e-01, Y0: 1.1620e-01,   elapsed time: 2572
 71%|███████   | 5700/8001 [43:28<13:43,  2.79it/s]step:  5700,    loss: 3.3301e-02, Y0: 1.1090e-01,   elapsed time: 2609
 72%|███████▏  | 5800/8001 [44:05<12:52,  2.85it/s]step:  5800,    loss: 6.5948e-02, Y0: 1.0996e-01,   elapsed time: 2646
 74%|███████▎  | 5900/8001 [44:42<13:55,  2.52it/s]step:  5900,    loss: 3.9473e-02, Y0: 1.1737e-01,   elapsed time: 2683
 75%|███████▍  | 6000/8001 [45:20<12:29,  2.67it/s]step:  6000,    loss: 1.5868e-01, Y0: 1.2008e-01,   elapsed time: 2721
 76%|███████▌  | 6100/8001 [46:02<13:28,  2.35it/s]step:  6100,    loss: 4.9755e-02, Y0: 1.3659e-01,   elapsed time: 2763
 77%|███████▋  | 6200/8001 [46:45<12:48,  2.34it/s]step:  6200,    loss: 8.4806e-02, Y0: 1.1983e-01,   elapsed time: 2806
 79%|███████▊  | 6300/8001 [47:27<11:58,  2.37it/s]step:  6300,    loss: 2.6973e-01, Y0: 1.2811e-01,   elapsed time: 2849
 80%|███████▉  | 6400/8001 [48:10<11:15,  2.37it/s]step:  6400,    loss: 4.9538e-02, Y0: 1.1907e-01,   elapsed time: 2892
 81%|████████  | 6500/8001 [48:53<10:29,  2.39it/s]step:  6500,    loss: 1.2063e-01, Y0: 1.2637e-01,   elapsed time: 2935
 82%|████████▏ | 6600/8001 [49:37<10:08,  2.30it/s]step:  6600,    loss: 3.1351e-02, Y0: 1.3382e-01,   elapsed time: 2978
 84%|████████▎ | 6700/8001 [50:20<09:23,  2.31it/s]step:  6700,    loss: 5.7911e-02, Y0: 1.3282e-01,   elapsed time: 3022
 85%|████████▍ | 6800/8001 [51:05<08:37,  2.32it/s]step:  6800,    loss: 1.2653e-01, Y0: 1.4014e-01,   elapsed time: 3067
 86%|████████▌ | 6900/8001 [51:50<07:49,  2.35it/s]step:  6900,    loss: 1.5038e-01, Y0: 1.4669e-01,   elapsed time: 3112
 87%|████████▋ | 7000/8001 [52:34<07:31,  2.21it/s]step:  7000,    loss: 3.8958e-02, Y0: 1.4259e-01,   elapsed time: 3156
 89%|████████▊ | 7100/8001 [53:19<06:29,  2.31it/s]step:  7100,    loss: 3.1593e-02, Y0: 1.4859e-01,   elapsed time: 3200
 90%|████████▉ | 7200/8001 [54:03<05:36,  2.38it/s]step:  7200,    loss: 3.1902e-02, Y0: 1.3700e-01,   elapsed time: 3244
 91%|█████████ | 7300/8001 [54:47<05:05,  2.29it/s]step:  7300,    loss: 2.7721e-02, Y0: 1.6370e-01,   elapsed time: 3289
 92%|█████████▏| 7400/8001 [55:32<04:24,  2.28it/s]step:  7400,    loss: 3.2783e-02, Y0: 1.4696e-01,   elapsed time: 3334
 94%|█████████▎| 7500/8001 [56:17<03:31,  2.37it/s]step:  7500,    loss: 9.8793e-02, Y0: 1.5789e-01,   elapsed time: 3378
 95%|█████████▍| 7600/8001 [57:01<02:51,  2.34it/s]step:  7600,    loss: 2.1895e-01, Y0: 1.1971e-01,   elapsed time: 3423
 96%|█████████▌| 7700/8001 [57:47<02:14,  2.24it/s]step:  7700,    loss: 1.1362e-01, Y0: 1.4298e-01,   elapsed time: 3468
 97%|█████████▋| 7800/8001 [58:32<01:31,  2.20it/s]step:  7800,    loss: 3.6921e-01, Y0: 1.4810e-01,   elapsed time: 3513
 99%|█████████▊| 7900/8001 [59:16<00:44,  2.28it/s]step:  7900,    loss: 3.1057e-02, Y0: 1.6905e-01,   elapsed time: 3557


100%|█████████▉| 8000/8001 [1:00:00<00:00,  2.18it/s]step:  8000,    loss: 2.7089e-01, Y0: 1.4998e-01,   elapsed time: 3602
100%|██████████| 8001/8001 [1:00:02<00:00,  2.22it/s]

mcprice = np.exp(-r* total_time)*np.average(np.maximum(stock[:,0,-1] - strike,0))

np.disp(mcprice)
0.1521948096681089



Removing all variables...
 

runfile('/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/script_call_optionCGMY.py', wdir='/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP')
Reloaded modules: PureJumpSolver, PureJumpEquation_CGMYprova, equation, tmpwr0pg5wy, tmphwf8qpt1, tmpgiqtm4m_, tmp9e9zfy_h, tmp9ju5ka34, tmp4x5fo3sh, tmpr8156udd, tmpo8lor8ew
/home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/PureJumpEquation_CGMYprova.py:287: RuntimeWarning: overflow encountered in exp
  T= np.exp(M*(X-eps))
  0%|          | 0/8001 [00:00<?, ?it/s]WARNING:tensorflow:AutoGraph could not transform <bound method NonsharedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7efef3556310>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <bound method NonsharedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7efef3556310>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f01dc0fa710> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f01dc0fa710> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <bound method NonsharedModel.predict_step of <tensorflow.python.eager.function.TfMethodTarget object at 0x7efec91effd0>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <bound method NonsharedModel.predict_step of <tensorflow.python.eager.function.TfMethodTarget object at 0x7efec91effd0>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
step:     0,    loss: 1.0636e+02, Y0: 5.3520e-02,   elapsed time: 133
WARNING:tensorflow:AutoGraph could not transform <bound method BSDESolver.train_step of <tensorflow.python.eager.function.TfMethodTarget object at 0x7efec91f6090>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <bound method BSDESolver.train_step of <tensorflow.python.eager.function.TfMethodTarget object at 0x7efec91f6090>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
  1%|          | 82/8001 [08:52<55:21,  2.38it/s]     /home/ptcmrc76/Desktop/Dati Python/20221005_Deep-Solver-master PureJump_ez_MP/PureJumpEquation_CGMYprova.py:292: RuntimeWarning: overflow encountered in exp
  T= np.exp(M*(X-eps))
  1%|          | 100/8001 [08:59<52:58,  2.49it/s]step:   100,    loss: 1.1780e-01, Y0: 1.4589e-01,   elapsed time: 540
  2%|▏         | 200/8001 [09:37<46:04,  2.82it/s]  step:   200,    loss: 5.5386e-02, Y0: 1.5586e-01,   elapsed time: 579
  4%|▎         | 300/8001 [10:14<46:38,  2.75it/s]  step:   300,    loss: 5.1274e-01, Y0: 9.8126e-02,   elapsed time: 616
  5%|▍         | 400/8001 [10:52<46:14,  2.74it/s]  step:   400,    loss: 1.1595e-01, Y0: 9.3371e-02,   elapsed time: 653
  6%|▌         | 500/8001 [11:31<47:34,  2.63it/s]  step:   500,    loss: 3.1625e-01, Y0: 8.1845e-02,   elapsed time: 692
  7%|▋         | 600/8001 [12:11<46:05,  2.68it/s]  step:   600,    loss: 1.4486e-01, Y0: 1.8512e-01,   elapsed time: 732
  9%|▊         | 700/8001 [12:50<46:18,  2.63it/s]  step:   700,    loss: 1.1572e+00, Y0: 2.5528e-01,   elapsed time: 771
 10%|▉         | 800/8001 [13:29<43:58,  2.73it/s]  step:   800,    loss: 1.0136e-01, Y0: 1.5585e-01,   elapsed time: 810
 11%|█         | 900/8001 [14:07<41:53,  2.82it/s]  step:   900,    loss: 8.4112e-02, Y0: 1.3076e-01,   elapsed time: 848
 12%|█▏        | 1000/8001 [14:44<43:28,  2.68it/s] step:  1000,    loss: 9.4123e-02, Y0: 1.7834e-01,   elapsed time: 886
 14%|█▎        | 1100/8001 [15:22<42:26,  2.71it/s]  step:  1100,    loss: 2.3340e-02, Y0: 1.2341e-01,   elapsed time: 923
 15%|█▍        | 1200/8001 [15:59<41:38,  2.72it/s]  step:  1200,    loss: 5.1993e-02, Y0: 1.5138e-01,   elapsed time: 960
 16%|█▌        | 1300/8001 [16:37<40:52,  2.73it/s]  step:  1300,    loss: 6.8766e-02, Y0: 1.4716e-01,   elapsed time: 998
 17%|█▋        | 1400/8001 [17:16<43:21,  2.54it/s]  step:  1400,    loss: 1.2113e-01, Y0: 2.3054e-01,   elapsed time: 1038
 19%|█▊        | 1500/8001 [17:53<37:39,  2.88it/s]  step:  1500,    loss: 2.0492e-01, Y0: 1.0675e-01,   elapsed time: 1074
 20%|█▉        | 1600/8001 [18:29<36:48,  2.90it/s]  step:  1600,    loss: 3.9237e-01, Y0: 1.0402e-01,   elapsed time: 1110
 21%|██        | 1700/8001 [19:05<36:45,  2.86it/s]step:  1700,    loss: 1.2447e-01, Y0: 4.8533e-02,   elapsed time: 1146
 22%|██▏       | 1800/8001 [19:40<35:12,  2.94it/s]step:  1800,    loss: 1.4821e-01, Y0: 1.9663e-01,   elapsed time: 1182
 24%|██▎       | 1900/8001 [20:16<35:40,  2.85it/s]step:  1900,    loss: 1.1098e-01, Y0: -2.6953e-03,   elapsed time: 1217
 25%|██▍       | 2000/8001 [20:51<35:55,  2.78it/s]step:  2000,    loss: 4.6704e-01, Y0: -4.2040e-03,   elapsed time: 1252
 26%|██▌       | 2100/8001 [21:26<33:31,  2.93it/s]step:  2100,    loss: 1.0621e+00, Y0: 3.1398e-01,   elapsed time: 1287
 27%|██▋       | 2200/8001 [22:02<32:58,  2.93it/s]step:  2200,    loss: 1.3758e-01, Y0: 2.1082e-01,   elapsed time: 1323
 29%|██▊       | 2300/8001 [22:37<33:27,  2.84it/s]step:  2300,    loss: 5.2322e-02, Y0: 1.8597e-01,   elapsed time: 1358
 30%|██▉       | 2400/8001 [23:14<36:11,  2.58it/s]step:  2400,    loss: 6.8001e-01, Y0: 1.1173e-01,   elapsed time: 1395
 31%|███       | 2500/8001 [23:50<30:48,  2.98it/s]step:  2500,    loss: 3.5634e-01, Y0: 5.2698e-01,   elapsed time: 1431
 32%|███▏      | 2600/8001 [24:25<31:03,  2.90it/s]step:  2600,    loss: 1.2244e+01, Y0: 2.3900e-01,   elapsed time: 1466
 34%|███▎      | 2700/8001 [25:00<29:39,  2.98it/s]step:  2700,    loss: 3.4400e-01, Y0: 1.7701e-01,   elapsed time: 1501
 35%|███▍      | 2800/8001 [25:35<30:27,  2.85it/s]step:  2800,    loss: 6.7066e+00, Y0: 1.1192e-01,   elapsed time: 1536
 36%|███▌      | 2900/8001 [26:10<29:06,  2.92it/s]step:  2900,    loss: 2.2317e-01, Y0: 1.5087e-01,   elapsed time: 1571
 37%|███▋      | 3000/8001 [26:45<28:29,  2.93it/s]step:  3000,    loss: 7.2174e-01, Y0: 1.5501e-01,   elapsed time: 1606
 39%|███▊      | 3100/8001 [27:21<29:03,  2.81it/s]step:  3100,    loss: 1.1805e-01, Y0: 1.2771e-01,   elapsed time: 1642
 40%|███▉      | 3200/8001 [27:55<26:22,  3.03it/s]step:  3200,    loss: 3.0509e-01, Y0: 1.9982e-01,   elapsed time: 1677
 41%|████      | 3300/8001 [28:33<28:52,  2.71it/s]step:  3300,    loss: 6.5928e-01, Y0: 1.7544e-01,   elapsed time: 1714
 42%|████▏     | 3400/8001 [29:11<27:37,  2.78it/s]step:  3400,    loss: 1.0119e-01, Y0: 1.3367e-01,   elapsed time: 1753
 44%|████▎     | 3500/8001 [29:50<28:26,  2.64it/s]step:  3500,    loss: 1.1125e+00, Y0: 1.2016e-01,   elapsed time: 1791
 45%|████▍     | 3600/8001 [30:28<27:50,  2.63it/s]step:  3600,    loss: 4.0048e-01, Y0: 1.3249e-01,   elapsed time: 1829
 46%|████▌     | 3700/8001 [31:06<27:12,  2.64it/s]step:  3700,    loss: 4.4012e-01, Y0: 1.3278e-01,   elapsed time: 1867
 47%|████▋     | 3800/8001 [31:44<26:26,  2.65it/s]step:  3800,    loss: 8.6110e-02, Y0: 1.4562e-01,   elapsed time: 1905
 49%|████▊     | 3900/8001 [32:21<25:29,  2.68it/s]step:  3900,    loss: 2.1483e-01, Y0: 1.2571e-01,   elapsed time: 1942
 50%|████▉     | 4000/8001 [32:58<23:42,  2.81it/s]step:  4000,    loss: 2.2694e-01, Y0: 1.3101e-01,   elapsed time: 1979
 51%|█████     | 4100/8001 [33:36<24:27,  2.66it/s]step:  4100,    loss: 1.9454e-02, Y0: 1.3220e-01,   elapsed time: 2017
 52%|█████▏    | 4200/8001 [34:14<23:24,  2.71it/s]step:  4200,    loss: 2.0988e-02, Y0: 1.3140e-01,   elapsed time: 2055
 54%|█████▎    | 4300/8001 [34:52<21:58,  2.81it/s]step:  4300,    loss: 1.5190e-02, Y0: 1.2961e-01,   elapsed time: 2094
 55%|█████▍    | 4400/8001 [35:30<23:10,  2.59it/s]step:  4400,    loss: 3.8996e-02, Y0: 1.3200e-01,   elapsed time: 2131
 56%|█████▌    | 4500/8001 [36:07<21:58,  2.65it/s]step:  4500,    loss: 1.2520e-02, Y0: 1.3259e-01,   elapsed time: 2168
 57%|█████▋    | 4600/8001 [36:46<21:34,  2.63it/s]step:  4600,    loss: 1.3530e-02, Y0: 1.3399e-01,   elapsed time: 2207
 59%|█████▊    | 4700/8001 [37:24<19:03,  2.89it/s]step:  4700,    loss: 5.6854e-02, Y0: 1.3404e-01,   elapsed time: 2245
 60%|█████▉    | 4800/8001 [38:01<20:02,  2.66it/s]step:  4800,    loss: 3.9015e-02, Y0: 1.3300e-01,   elapsed time: 2283
 61%|██████    | 4900/8001 [38:40<19:18,  2.68it/s]step:  4900,    loss: 1.0974e-02, Y0: 1.3390e-01,   elapsed time: 2321
 62%|██████▏   | 5000/8001 [39:17<18:37,  2.69it/s]step:  5000,    loss: 1.7460e-02, Y0: 1.3497e-01,   elapsed time: 2359
 64%|██████▎   | 5100/8001 [39:55<17:15,  2.80it/s]step:  5100,    loss: 5.5352e-02, Y0: 1.3741e-01,   elapsed time: 2396
 65%|██████▍   | 5200/8001 [40:33<18:30,  2.52it/s]step:  5200,    loss: 1.9841e-02, Y0: 1.3892e-01,   elapsed time: 2434
 66%|██████▌   | 5300/8001 [41:12<18:26,  2.44it/s]step:  5300,    loss: 2.6217e-02, Y0: 1.3673e-01,   elapsed time: 2473
 67%|██████▋   | 5400/8001 [41:50<16:12,  2.68it/s]step:  5400,    loss: 6.0224e-02, Y0: 1.3404e-01,   elapsed time: 2511
 69%|██████▊   | 5500/8001 [42:28<15:52,  2.62it/s]step:  5500,    loss: 1.4788e-01, Y0: 1.3283e-01,   elapsed time: 2549
 70%|██████▉   | 5600/8001 [43:08<14:41,  2.72it/s]step:  5600,    loss: 8.4883e-02, Y0: 1.4035e-01,   elapsed time: 2589
 71%|███████   | 5700/8001 [43:45<14:20,  2.67it/s]step:  5700,    loss: 4.6339e-01, Y0: 1.2334e-01,   elapsed time: 2627
 72%|███████▏  | 5800/8001 [44:23<14:00,  2.62it/s]step:  5800,    loss: 2.2050e-02, Y0: 1.3416e-01,   elapsed time: 2664
 74%|███████▎  | 5900/8001 [45:02<13:23,  2.62it/s]step:  5900,    loss: 2.8904e-02, Y0: 1.3923e-01,   elapsed time: 2703
 75%|███████▍  | 6000/8001 [45:42<13:08,  2.54it/s]step:  6000,    loss: 1.7860e-02, Y0: 1.4149e-01,   elapsed time: 2743
 76%|███████▌  | 6100/8001 [46:20<11:39,  2.72it/s]step:  6100,    loss: 3.6885e-02, Y0: 1.4112e-01,   elapsed time: 2781
 77%|███████▋  | 6200/8001 [46:58<10:50,  2.77it/s]step:  6200,    loss: 8.1718e-02, Y0: 1.3998e-01,   elapsed time: 2819
 79%|███████▊  | 6300/8001 [47:35<10:54,  2.60it/s]step:  6300,    loss: 2.5109e-02, Y0: 1.4563e-01,   elapsed time: 2856
 80%|███████▉  | 6400/8001 [48:12<09:27,  2.82it/s]step:  6400,    loss: 3.2517e-02, Y0: 1.4799e-01,   elapsed time: 2894
 81%|████████  | 6500/8001 [48:50<09:28,  2.64it/s]step:  6500,    loss: 4.3773e-02, Y0: 1.4860e-01,   elapsed time: 2931
 82%|████████▏ | 6600/8001 [49:27<08:46,  2.66it/s]step:  6600,    loss: 6.0974e-02, Y0: 1.4864e-01,   elapsed time: 2969
 84%|████████▎ | 6700/8001 [50:07<08:25,  2.57it/s]step:  6700,    loss: 8.9725e-02, Y0: 1.4928e-01,   elapsed time: 3008
 85%|████████▍ | 6800/8001 [50:47<07:47,  2.57it/s]step:  6800,    loss: 1.3977e-02, Y0: 1.5232e-01,   elapsed time: 3048
 86%|████████▌ | 6900/8001 [51:25<07:13,  2.54it/s]step:  6900,    loss: 2.2809e-02, Y0: 1.5158e-01,   elapsed time: 3086
 87%|████████▋ | 7000/8001 [52:04<06:33,  2.54it/s]step:  7000,    loss: 1.8889e-02, Y0: 1.5878e-01,   elapsed time: 3125
 89%|████████▊ | 7100/8001 [52:43<05:40,  2.65it/s]step:  7100,    loss: 4.0760e-02, Y0: 1.5318e-01,   elapsed time: 3164
 90%|████████▉ | 7200/8001 [53:21<05:01,  2.66it/s]step:  7200,    loss: 4.1343e-01, Y0: 1.4639e-01,   elapsed time: 3202
 91%|█████████ | 7300/8001 [54:00<04:21,  2.68it/s]step:  7300,    loss: 1.6237e-02, Y0: 1.5913e-01,   elapsed time: 3241
 92%|█████████▏| 7400/8001 [54:38<03:44,  2.67it/s]step:  7400,    loss: 3.4038e-02, Y0: 1.6082e-01,   elapsed time: 3279
 94%|█████████▎| 7500/8001 [55:16<03:05,  2.70it/s]step:  7500,    loss: 8.1762e-02, Y0: 1.6152e-01,   elapsed time: 3317
 95%|█████████▍| 7600/8001 [55:54<02:33,  2.61it/s]step:  7600,    loss: 2.6314e-01, Y0: 1.5778e-01,   elapsed time: 3355
 96%|█████████▌| 7700/8001 [56:32<01:51,  2.70it/s]step:  7700,    loss: 1.4554e-02, Y0: 1.5335e-01,   elapsed time: 3393
 97%|█████████▋| 7800/8001 [57:09<01:12,  2.77it/s]step:  7800,    loss: 2.4507e-02, Y0: 1.5137e-01,   elapsed time: 3430
 99%|█████████▊| 7900/8001 [57:47<00:37,  2.69it/s]step:  7900,    loss: 1.3259e-02, Y0: 1.6429e-01,   elapsed time: 3468
100%|█████████▉| 8000/8001 [58:24<00:00,  2.71it/s]step:  8000,    loss: 1.8492e-02, Y0: 1.6096e-01,   elapsed time: 3505
100%|██████████| 8001/8001 [58:25<00:00,  2.28it/s]
0.18417869485991897

